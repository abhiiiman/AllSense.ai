import streamlit as st
from elevenlabs.client import ElevenLabs
from elevenlabs import play, stream
import os
from dotenv import load_dotenv
from langchain_ollama import OllamaLLM  # Updated import based on the warning

# Load environment variables
load_dotenv()

# Initialize ElevenLabs client
client = ElevenLabs(api_key=os.getenv("ELEVEN_API_KEY"))

# Initialize Ollama model
cached_llm = OllamaLLM(model="llama3.2:1b", base_url="http://localhost:11434")

def process_query(query):
    """
    Processes a query by generating a spoken response for the query and the LLM output.

    Args:
        query (str): The input query from the user.

    Returns:
        tuple: The response from the LLM and the file paths of the generated audio files.
    """
    print(f"You asked: {query}")

    # Generate audio for the query
    print("Generating audio for the query...")
    query_audio_path = "query_audio.mp3"
    audio_stream = client.generate(text="You asked: " + query, stream=True)
    with open(query_audio_path, "wb") as f:
        for chunk in audio_stream:
            f.write(chunk)

    # Query the LLM
    print("Querying the LLM...")
    response = cached_llm.invoke(query)

    # Display the LLM's response
    print(f"LLM response: {response}")

    # Generate audio for the LLM response
    print("Generating audio for the LLM response...")
    response_audio_path = "response_audio.mp3"
    audio_stream = client.generate(text=response, stream=True)
    with open(response_audio_path, "wb") as f:
        for chunk in audio_stream:
            f.write(chunk)

    return response, query_audio_path, response_audio_path

# Streamlit app
def main():
    st.title("SpeakLLM: Interactive Chat with Audio")
    st.markdown("Type your query below and interact with the LLM. Listen to the audio responses generated by the system.")

    query = st.text_input("Your query:", "")

    if st.button("Submit") and query:
        with st.spinner("Processing your query..."):
            try:
                response, query_audio_path, response_audio_path = process_query(query)
                
                st.markdown("### Your Query")
                st.audio(query_audio_path, format="audio/mp3")

                st.markdown("### LLM Response")
                st.text(response)
                st.audio(response_audio_path, format="audio/mp3")
            except Exception as e:
                st.error(f"An error occurred: {e}")

if __name__ == "__main__":
    main()
